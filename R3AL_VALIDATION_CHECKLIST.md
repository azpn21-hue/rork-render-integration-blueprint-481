# R3AL Psych-Eval Questionnaire â€” Validation Checklist

## âœ… Implementation Status

**All systems deployed and integrated.**

---

## ðŸ“‹ Schema Validation

### âœ… Questionnaire Schema (`schemas/r3al/questionnaire_schema.json`)

- [x] Version 2.0.0 confirmed
- [x] 8 sections defined
- [x] 24+ questions total
- [x] Question types: single, multi, scale, number, free text, user-defined
- [x] Required fields marked
- [x] Meta tags for lie-scale items
- [x] Optional section configured
- [x] Attention check injected after `cc_gray_zone`
- [x] Consistency check rules defined
- [x] Timing rules enabled (minMsPerItem: 800)

### âœ… Truth-Score Schema (`schemas/r3al/truthscore_schema.json`)

- [x] Composite model enabled
- [x] 5 subscales defined (Integrity, Safety, Transparency, Stability, RiskHistory)
- [x] Weights configured per question
- [x] Lie-scale detection active
- [x] Attention check penalty (-3)
- [x] Consistency penalty (-1 per conflict)
- [x] Timing penalty (-1 for fast burst)
- [x] Score normalization (0-100)
- [x] 3 levels defined (Low, Medium, High)
- [x] Risk flags: fakingGood, LegalHistory, AggressiveConflict
- [x] Output paths configured
- [x] RiseN_AI + Optima_II integrations referenced

### âœ… App Schema (`schemas/r3al/app_schema.json`)

- [x] Questionnaire screen UI settings added
- [x] Optional toggle key: `show_optional_deep_disclosure`
- [x] Progress bar enabled
- [x] Per-page mode active
- [x] Back navigation allowed
- [x] Save-as-you-go enabled
- [x] Accent color: `#D4AF37`
- [x] Accessibility features: captions, larger tap targets
- [x] Scoring reference: `./truthscore_schema.json`

### âœ… Locale Tokens (`schemas/r3al/locale_tokens.json`)

- [x] English translations complete
- [x] Spanish translations complete
- [x] Section titles localized (8 sections)
- [x] Subscale names localized (5 subscales)
- [x] Risk flag labels localized (3 flags)
- [x] Toggle label localized
- [x] Privacy note localized

---

## ðŸ§ª Functional Testing Matrix

### **Section Coverage**

| Section ID | Questions | Tested? | Notes |
|-----------|-----------|---------|-------|
| `identity_integrity` | 4 | â¬œ | Includes lie-scale item |
| `relationship_history_risk` | 4 | â¬œ | Includes restraining order (risk flag) |
| `boundaries_safety` | 3 | â¬œ | Includes conflict style (risk flag) |
| `communication_conflict` | 3 | â¬œ | Includes consistency pair |
| `lifestyle_stability` | 3 | â¬œ | Includes multi-select substance use |
| `digital_footprint_privacy` | 2 | â¬œ | Includes catfish history |
| `values_dealbreakers` | 2 | â¬œ | Includes free text + multi-select |
| `optional_deep_disclosure` | 2 | â¬œ | **Optional** â€” requires toggle |

### **Question Type Testing**

| Type | Example Question | Tested? |
|------|------------------|---------|
| `single` | "First meetings in public?" | â¬œ |
| `multi` | "Current substance use?" | â¬œ |
| `scale` | "Honesty under cost (1-5)" | â¬œ |
| `number` | "# of relationships" | â¬œ |
| `free` | "3 non-negotiables" | â¬œ |
| `user_defined` | "Custom truth question" | â¬œ |

### **Scoring Features**

| Feature | Test Case | Expected Result | Tested? |
|---------|-----------|----------------|---------|
| **Lie Detection** | Claim "never lied" + "always honest" | Flag `fakingGood`, -2 penalty | â¬œ |
| **Attention Check** | Select "No" on attention question | -3 penalty | â¬œ |
| **Consistency** | Conflicting lie-scale answers | -1 penalty per pair | â¬œ |
| **Timing** | Answer all questions < 800ms each | -1 penalty | â¬œ |
| **Risk Flag: Legal** | "Yes" on restraining order | Tag `LegalHistory` | â¬œ |
| **Risk Flag: Aggressive** | "Confront aggressively" on conflict | Tag `AggressiveConflict` | â¬œ |
| **Score Range** | Various answer combinations | 0-39, 40-69, 70-100 | â¬œ |

### **UI/UX Features**

| Feature | Expected Behavior | Tested? |
|---------|-------------------|---------|
| **Progress Bar** | Shows `X of Y` sections | â¬œ |
| **Back Button** | Returns to previous question | â¬œ |
| **Save Progress** | Persists answers on app close | â¬œ |
| **Optional Toggle** | Shows/hides deep disclosure section | â¬œ |
| **Accent Color** | Gold (#D4AF37) on active elements | â¬œ |
| **Accessibility** | Captions + larger tap targets | â¬œ |

### **Localization**

| Language | Section Titles | Question Labels | Flag Labels | Tested? |
|----------|---------------|-----------------|-------------|---------|
| English | âœ… | âœ… | âœ… | â¬œ |
| Spanish | âœ… | âœ… | âœ… | â¬œ |

---

## ðŸ”¬ Edge Case Scenarios

### **Scenario 1: Perfect Score Attempt**
**Setup:**
- Answer "Yes" to all positive integrity questions
- Select "Never" on all negative questions
- Claim "never told a lie" (True)
- Claim "always honest about trivial things" (True)

**Expected:**
- High raw score (~85-90)
- **BUT:** Flag `fakingGood` triggered
- Penalty: -2 (lie-scale)
- Final score: ~83-88 â†’ **High** but with warning

**Status:** â¬œ Not Tested

---

### **Scenario 2: High-Risk Profile**
**Setup:**
- Select "Yes" on restraining order question
- Choose "Confront aggressively" on conflict escalation
- Select "Yes (recently)" on catfish question

**Expected:**
- Risk flags: `LegalHistory`, `AggressiveConflict`
- Penalties: -2 (restraining order) + -1 (aggression) + -1 (catfish)
- Score likely: 30-50 â†’ **Low to Medium**
- Flags visible in result screen

**Status:** â¬œ Not Tested

---

### **Scenario 3: Rushed Responses**
**Setup:**
- Answer each question in < 500ms
- Complete entire questionnaire in < 2 minutes

**Expected:**
- Timing penalty: -1 for fast-burst detection
- Possible attention check failure if rushed
- Additional -3 penalty if attention check failed
- Score reduced by 4-5 points total

**Status:** â¬œ Not Tested

---

### **Scenario 4: Inconsistent Answers**
**Setup:**
- "I never told a lie" = True
- "In what situations okay to hide facts?" = "Sometimes"
- "I am always honest" = False

**Expected:**
- Consistency check triggers
- Penalty: -1 per conflicting pair
- Score reduced by 1-2 points
- May contribute to `fakingGood` flag

**Status:** â¬œ Not Tested

---

### **Scenario 5: Optional Section Toggle**
**Setup:**
- **Test A:** Toggle OFF â†’ Complete questionnaire
- **Test B:** Toggle ON â†’ Complete with optional section

**Expected:**
- **Test A:** Only 7 sections shown, score based on core questions
- **Test B:** 8 sections shown, optional answers included in transparency scoring

**Status:** â¬œ Not Tested

---

## ðŸ“Š Score Calculation Verification

### **Manual Calculation Example**

**User Answers:**
- `id_name_match`: Yes â†’ +2
- `id_verif_consent`: Yes â†’ +3
- `cc_honesty_under_cost`: 4/5 â†’ +4
- `bs_first_meet_public`: Always â†’ +1
- `bs_location_share`: Yes â†’ +1
- `ls_financial_transparency`: Yes â†’ +2
- `vd_disclosures`: 3 items selected â†’ +3
- `rh_overlap`: No â†’ +1
- `rh_order_restrain`: No â†’ +1
- `id_liescale_perfect`: False â†’ 0 (no penalty)
- Attention check: Correct â†’ 0 penalty
- Timing: Normal â†’ 0 penalty

**Raw Total:** 2 + 3 + 4 + 1 + 1 + 2 + 3 + 1 + 1 = **18 points**

**Normalization:** (18 / max_possible) Ã— 100 = **~72/100**

**Expected Level:** ðŸŸ¢ **High** (70-100 range)

**Status:** â¬œ Not Verified

---

## ðŸ” Privacy & Security Checks

| Feature | Implementation | Verified? |
|---------|---------------|-----------|
| **Encryption at Rest** | Responses encrypted in storage | â¬œ |
| **Mutual Consent Reveal** | Sensitive disclosures gated | â¬œ |
| **Optional Opt-In** | Deep disclosure requires explicit toggle | â¬œ |
| **User Edits** | Can review/change answers before submit | â¬œ |
| **Transparent Scoring** | Subscales + flags shown to user | â¬œ |
| **Data Minimization** | Only necessary data collected | â¬œ |

---

## ðŸš¨ Known Limitations

### **Current Constraints:**
1. **Client-Side Scoring:** Calculations done in-app (can be inspected by savvy users)
2. **Self-Reported Data:** No external validation of responses
3. **Static Weights:** Scoring weights are fixed (not adaptive)
4. **English/Spanish Only:** Other languages not yet supported

### **Mitigations:**
- RiseN_AI + Optima_II backend hooks can add server-side validation
- Lie-scale + consistency checks catch some dishonesty
- Timing analysis reduces thoughtless responses
- Localization framework allows easy language additions

---

## ðŸ“ Recommended Testing Sequence

### **Phase 1: Schema Validation**
1. âœ… Verify all JSON schemas parse correctly
2. âœ… Confirm question IDs are unique
3. âœ… Check all referenced locale keys exist
4. âœ… Validate scoring weight completeness

### **Phase 2: UI Flow Testing**
1. â¬œ Load questionnaire screen
2. â¬œ Navigate through all 8 sections
3. â¬œ Test back button behavior
4. â¬œ Toggle optional section on/off
5. â¬œ Complete and submit

### **Phase 3: Scoring Testing**
1. â¬œ Submit with known answer set
2. â¬œ Manually calculate expected score
3. â¬œ Compare with app-generated score
4. â¬œ Verify subscale breakdown
5. â¬œ Confirm flags display correctly

### **Phase 4: Edge Case Testing**
1. â¬œ Run Scenario 1 (Perfect Score)
2. â¬œ Run Scenario 2 (High Risk)
3. â¬œ Run Scenario 3 (Rushed)
4. â¬œ Run Scenario 4 (Inconsistent)
5. â¬œ Run Scenario 5 (Optional Toggle)

### **Phase 5: Localization Testing**
1. â¬œ Switch to Spanish locale
2. â¬œ Verify section titles translate
3. â¬œ Verify question labels translate
4. â¬œ Verify flag labels translate
5. â¬œ Check for any missing keys

---

## âœ… Sign-Off Checklist

### **Pre-Production:**
- [ ] All schemas validated
- [ ] End-to-end questionnaire flow tested
- [ ] Score calculations verified
- [ ] Risk flags tested
- [ ] Anomaly detection verified
- [ ] Privacy controls confirmed
- [ ] Both languages tested
- [ ] Edge cases documented
- [ ] User acceptance testing complete
- [ ] Performance profiling done

### **Production Launch:**
- [ ] Monitoring dashboard configured
- [ ] Error logging active
- [ ] Analytics tracking enabled
- [ ] User feedback mechanism ready
- [ ] Support documentation published
- [ ] Rollback plan prepared

---

## ðŸ“ž Validation Support

**For Test Execution:**
```bash
# Start app
npm start

# View schemas
cat schemas/r3al/questionnaire_schema.json
cat schemas/r3al/truthscore_schema.json
```

**For Issues:**
- Schema errors â†’ Check `schemas/r3al/` files
- Scoring bugs â†’ Review `truthscore_schema.json` weights
- UI problems â†’ Check `app_schema.json` UI config
- Translation gaps â†’ Update `locale_tokens.json`

---

**Validation Version:** 1.0  
**Created:** 2025-11-02  
**Status:** â¬œ Awaiting Test Execution
